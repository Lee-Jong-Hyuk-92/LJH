{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  GPT가 작성한 최적화된 로지스틱 회귀 전체 코드\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # 불필요한 경고 무시하는 기능\n",
    "\n",
    "import pandas as pd # 데이터 읽기\n",
    "import seaborn as sns # 이쁘게 출력, 기본출력이 있어야만 가능\n",
    "import matplotlib.pyplot as plt # 기본출력\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 불러오기\n",
    "file_path = \"data.csv\"  # 파일 경로 설정\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 불필요한 열 제거 (id, Unnamed: 32)\n",
    "df = df.drop(columns=['id', 'Unnamed: 32'])\n",
    "\n",
    "# diagnosis를 0과 1로 변환 (M=1, B=0)\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# diagnosis와의 상관관계 분석 후 상위 20개 피처 선택\n",
    "correlation = df.corr()['diagnosis'].abs().sort_values(ascending=False)\n",
    "top_features = correlation.index[1:21]  # diagnosis 제외하고 상위 20개 선택\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np # corr 0.9이상 자동 제거 함수 만들려고\n",
    "# 상관관계 높은 피처 자동 제거 (0.9 이상)\n",
    "def remove_highly_correlated_features(df, threshold=0.9):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    print(f\"🛠 제거된 피처들 (상관관계 {threshold} 이상): {to_drop}\")\n",
    "    return df.drop(columns=to_drop)\n",
    "\n",
    "df_reduced = remove_highly_correlated_features(df[top_features])\n",
    "\n",
    "# 최종 선택된 피처\n",
    "selected_features = df_reduced.columns.tolist()\n",
    "print(f\"\\n✅ 최종 선택된 피처들: {selected_features}\")\n",
    "\n",
    "# 데이터셋 생성\n",
    "X = df[selected_features]\n",
    "y = df['diagnosis']\n",
    "\n",
    "# 데이터 분할 (훈련 80%, 테스트 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 표준화 (StandardScaler 적용)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 최적의 C 값 찾기 (GridSearchCV)\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_c = grid_search.best_params_['C']\n",
    "print(f\"\\n✅ 최적의 C 값: {best_c}\")\n",
    "\n",
    "# 최적의 C 값을 사용하여 로지스틱 회귀 모델 학습\n",
    "model = LogisticRegression(C=best_c, max_iter=10000, solver='lbfgs')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측 및 정확도 평가\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n✅ 최적화된 로지스틱 회귀 모델 정확도: {accuracy:.4f}\")\n",
    "\n",
    "# 예측 결과 DataFrame 생성\n",
    "df_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "# countplot 시각화\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Predicted', hue='Actual', data=df_results, palette=\"viridis\")\n",
    "plt.title('Actual vs Predicted Diagnosis')\n",
    "plt.xlabel('Predicted Diagnosis (0: Benign, 1: Malignant)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title=\"Actual\", labels=[\"Benign (0)\", \"Malignant (1)\"])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
